# TTS QA ìë™í™” í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ê³„íšì„œ

## ğŸ¯ í˜„ì¬ ì§„í–‰ ìƒí™© (2025-08-23) - COMPLETE AUDIO REQUIREMENTS

### âœ… ì™„ë£Œëœ ì‘ì—…
1. **emotion_label ê¸°ë°˜ ìŒì„± ìƒì„± ì™„ë£Œ**
   - 258ê°œ ìŒì„± íŒŒì¼ ì„±ê³µì ìœ¼ë¡œ ìƒì„± (public/voices/)
   - 6ê°œ emotion_labels (angry, sad, happy, whisper, toneup, tonedown)
   - v001, v002 voiceë³„ë¡œ ìƒì„± ì™„ë£Œ

2. **emotion_vector_id ì„¤ì • ë° í…ŒìŠ¤íŠ¸**
   - ìƒˆë¡œìš´ emotion_vector_ids ìƒì„± ë° ê²€ì¦ ì™„ë£Œ
   - API ì—°ë™ í…ŒìŠ¤íŠ¸ ì„±ê³µ (dev.icepeak.ai)
   - í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸: bp_c_l=true, style_label="normal-1"
   - emotion_vector ê¸°ë°˜ 88ê°œ íŒŒì¼ ìƒì„± ì™„ë£Œ (40% ì§„í–‰)

3. **ë³´ì•ˆ ì„¤ì • ì™„ë£Œ**
   - .gitignore ì—…ë°ì´íŠ¸ë¡œ ë¯¼ê° ì •ë³´ ë³´í˜¸
   - API í† í° ë° ê°œì¸ ì •ë³´ ì œì™¸
   - Vercel ë°°í¬ í™˜ê²½ ìœ ì§€

### ğŸš€ ìƒˆë¡œìš´ ëª©í‘œ: Expressivity ë¹„êµ í…ŒìŠ¤íŠ¸
**ëª©ì **: expressivity íŒŒë¼ë¯¸í„° íš¨ê³¼ ì¸¡ì •
- **expressivity_none**: ê¸°ë³¸ ë²„ì „ (í˜„ì¬ ìƒì„± ë°©ì‹)
- **expressivity_0.6**: ëª¨ë“  í…ìŠ¤íŠ¸ì— "|0.6" ì ‘ë¯¸ì‚¬ ì¶”ê°€

**í™•ì¥ëœ í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤**:
```
ì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ = 1,728ê°œ
- expressivity ë²„ì „: 2ê°œ (none, 0.6)
- voice_id: 2ê°œ (v001, v002)  
- emotion íƒ€ì…: 12ê°œ (6 emotion_labels + 6 emotion_vectors)
- text íƒ€ì…: 3ê°œ (match, neutral, opposite)
- emotion_scale: 6ê°œ (0.5, 1.0, 1.5, 2.0, 2.5, 3.0)
```

### ğŸ”§ ì§„í–‰ ì¤‘ì¸ ì‘ì—… (2025-08-23)
- **Complete Reference ì˜¤ë””ì˜¤ ìƒì„±**
  - 144ê°œ reference ì˜¤ë””ì˜¤ ìƒì„± ì¤‘ (72 Ã— 2 expressivity)
  - ê° emotion Ã— text_type ì¡°í•©ì˜ ê³ ìœ  í…ìŠ¤íŠ¸ ì‚¬ìš©
  - ReferenceëŠ” ê°ì • ì—†ëŠ” ì¤‘ë¦½ baseline (style_label="normal-1" only)
  
- **ì˜¤ë””ì˜¤ íŒŒì¼ ìµœì¢… êµ¬ì„±**
  - Target audios: 864ê°œ (432 Ã— 2 expressivity) 
  - Reference audios: 144ê°œ (72 Ã— 2 expressivity)
  - ì´ 1,008ê°œ ì˜¤ë””ì˜¤ íŒŒì¼

### ğŸ“Š í•µì‹¬ ì°¨ë³„ì  (ì´ë²ˆ ì‹¤í—˜ ì„¤ê³„)
1. **í…ìŠ¤íŠ¸ ê³ ìœ ì„±**: ê° emotion Ã— text_type ì¡°í•©ì´ ê³ ìœ í•œ í…ìŠ¤íŠ¸ ì‚¬ìš© (72ê°œ ê³ ìœ  í…ìŠ¤íŠ¸)
2. **ì •í™•í•œ Reference ë§¤ì¹­**: voice_id + emotion + text_typeìœ¼ë¡œ ì •í™•íˆ ë§¤ì¹­
3. **Expressivity ë¹„êµ**: ë™ì¼ í…ìŠ¤íŠ¸ë¡œ none vs 0.6 íš¨ê³¼ ì¸¡ì • ê°€ëŠ¥
4. **Scale íš¨ê³¼ ë¶„ì„**: ê° referenceì™€ 6ê°œ scale ë¹„êµë¡œ ê°ì • ê°•ë„ íš¨ê³¼ ì¸¡ì •

### ğŸ“ ì£¼ìš” ë³€ê²½ì‚¬í•­
- **Actor IDs ì—…ë°ì´íŠ¸**: 
  - v001: 688b02990486383d463c9d1a (male)
  - v002: 689c69984c7990a1ddca2327 (female)
- **emotion_vector_ids ì „ì²´ êµì²´** (ìœ„ ì°¸ì¡°)
- **API íŒŒë¼ë¯¸í„° ìˆ˜ì •**: emotion_label ì œê±°, bp_c_l ì¶”ê°€

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
Text-to-Speech ëª¨ë¸ì˜ í’ˆì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ ê²€ì¦í•˜ê¸° ìœ„í•œ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

### í•µì‹¬ ëª©í‘œ
1. ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ì— ëŒ€í•œ ìŒì„± ìë™ ìƒì„±
2. Reference ìŒì„± ëŒ€ë¹„ í’ˆì§ˆ í‰ê°€
3. ë³€ìˆ˜ë³„ ì˜í–¥ë„ íŒŒì•… ë° ë¬¸ì œ íŒ¨í„´ ì‹ë³„

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ - COMPLETE AUDIO REQUIREMENTS

#### 1.1 Target Audio Requirements (ê°ì •ì´ ì ìš©ëœ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤)
```
ì´ Target ì˜¤ë””ì˜¤ = 864ê°œ (432ê°œ Ã— 2 expressivity types)
- voice_id: 2ê°œ (v001, v002)
- emotions: 12ê°œ (emotion_label 6ê°œ + emotion_vector_id 6ê°œ)
- text_types: 3ê°œ (match, neutral, opposite) - ê° ê°ì •ë³„ë¡œ ë‹¤ë¥¸ í…ìŠ¤íŠ¸
- emotion_scale: 6ë‹¨ê³„ (0.5, 1.0, 1.5, 2.0, 2.5, 3.0)
- expressivity: 2ê°œ (none, 0.6)

ê³„ì‚°: 2 voices Ã— 12 emotions Ã— 3 text_types Ã— 6 scales Ã— 2 expressivity = 864ê°œ
```

#### 1.2 Reference Audio Requirements (ì¤‘ë¦½ baseline ì˜¤ë””ì˜¤)
```
ì´ Reference ì˜¤ë””ì˜¤ = 144ê°œ (72ê°œ Ã— 2 expressivity types)
- voice_id: 2ê°œ (v001, v002)
- emotions: 12ê°œ (ê° ê°ì •ì˜ ê³ ìœ  í…ìŠ¤íŠ¸ ì‚¬ìš©)
- text_types: 3ê°œ (match, neutral, opposite) - ê°ê° ë‹¤ë¥¸ í…ìŠ¤íŠ¸
- expressivity: 2ê°œ (none, 0.6)
- ì„¤ì •: style_label="normal-1" only (no emotion)

ê³„ì‚°: 2 voices Ã— 12 emotions Ã— 3 text_types Ã— 2 expressivity = 144ê°œ

ì¤‘ìš”: ê° referenceëŠ” ë™ì¼í•œ voice_id, emotion, text_typeì„ ê°€ì§„ 
      6ê°œì˜ ë‹¤ë¥¸ scale target ì˜¤ë””ì˜¤ì™€ ë¹„êµë¨
```

#### 1.3 ì´ ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜
```
ì´ ì˜¤ë””ì˜¤ íŒŒì¼ = 1,008ê°œ
- Target audios: 864ê°œ
- Reference audios: 144ê°œ
```

#### íŒŒë¼ë¯¸í„° ìƒì„¸

**Emotion êµ¬ì„± (12ê°œ)**
```yaml
emotion_labels: 
  - angry    # "I can't believe you broke your promise again!"
  - sad      # "I really miss the old days when everyone was here together."
  - happy    # "I'm so thrilled about the wonderful surprise party!"
  - whisper  # "Don't make any noise, everyone is sleeping in the next room."
  - toneup   # "Did you really win the grand prize in the competition?"
  - tonedown # "Let me explain this matter in a very serious manner."

emotion_vector_ids (UPDATED 2025-08-22):
  - 68a7b5995b2b44d11cede93c  # Excited: "We're going on the adventure of a lifetime!"
  - 68a7b5a418fc7f54efec5b2f  # Furious: "This is absolutely unacceptable and I demand an explanation!"
  - 68a7b5acb4a6c41c56a161e9  # Terrified: "Something is moving in the shadows and I don't know what!"
  - 68a7b5beb4a6c41c56a161ea  # ë‘ë ¤ì›€: "I'm really scared about what might happen if this goes wrong."
  - 68a7b5c218fc7f54efec5b31  # ë†€ëŒ: "Oh my goodness, I never expected to see you here today!"
  - 68a7b5c5b4a6c41c56a161eb  # í¥ë¶„: "I can hardly wait to share this amazing news with everyone!"

emotion_scales: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

text_types: [match, neutral, opposite]  # ê°ì • ì¼ì¹˜, ì¤‘ë¦½, ë°˜ëŒ€
```

#### íŒŒë¼ë¯¸í„° ê·œì¹™
- `style_label`ê³¼ `emotion_vector_id`ëŠ” ìƒí˜¸ ë°°íƒ€ì 
- `emotion_vector_id` ì‚¬ìš© ì‹œ â†’ `style_label = "normal-1"`
- `style_label â‰  "normal-1"` ì‹œ â†’ `emotion_vector_id` ì œê±°
- `emotion_scale`ì€ `emotion_vector_id` ì‚¬ìš© ì‹œì—ë§Œ ì ìš©

#### Reference ìŒì„± ì •ì˜ (CORRECTED 2025-08-23)
**í•µì‹¬ ì›ì¹™**: ReferenceëŠ” ê°ì •ì´ ì—†ëŠ” ì¤‘ë¦½ì  baseline
- ê° `voice_id Ã— text` ì¡°í•©ë‹¹ 1ê°œì˜ reference ìŒì„±
- ì„¤ì •:
  - `style_label: "normal-1"` (í•„ìˆ˜)
  - `emotion_label: null` (ê°ì • ë¼ë²¨ ì—†ìŒ)
  - `emotion_vector_id: null` (ê°ì • ë²¡í„° ì—†ìŒ)
  - `emotion_scale: 1.0` (ê¸°ë³¸ê°’)
- **ë§¤ì¹­ ê·œì¹™**: 
  - í•˜ë‚˜ì˜ referenceëŠ” ë™ì¼í•œ voice_idì™€ textë¥¼ ê°€ì§„ 6ê°œ scaleì˜ target ì˜¤ë””ì˜¤ì™€ ë¹„êµ
  - ì˜ˆ: v001_match_reference.wavëŠ” v001_match_emo_angryì˜ ëª¨ë“  scale (0.5~3.0)ê³¼ ë¹„êµ

### 2. íŒŒì¼ëª… ê·œì¹™ (COMPLETE SPECIFICATION)

```
Target ì˜¤ë””ì˜¤ í˜•ì‹: {voice_id}_{text_type}_{emotion_type}_{emotion_value}_scale_{scale}.wav
Reference ì˜¤ë””ì˜¤ í˜•ì‹: {voice_id}_{text_type}_reference_{emotion}.wav

ì˜ˆì‹œ - Target ì˜¤ë””ì˜¤:
- emotion_label: v001_match_emo_angry_scale_1.5.wav
- emotion_vector: v001_neutral_vec_excited_scale_2.0.wav

ì˜ˆì‹œ - Reference ì˜¤ë””ì˜¤:
- v001_match_reference_angry.wav (angryì˜ match í…ìŠ¤íŠ¸, ê°ì • ì—†ìŒ)
- v001_neutral_reference_sad.wav (sadì˜ neutral í…ìŠ¤íŠ¸, ê°ì • ì—†ìŒ)
- v002_opposite_reference_happy.wav (happyì˜ opposite í…ìŠ¤íŠ¸, ê°ì • ì—†ìŒ)

í´ë” êµ¬ì¡°:
public/voices/
â”œâ”€â”€ expressivity_none/      # ê¸°ë³¸ í…ìŠ¤íŠ¸
â”‚   â”œâ”€â”€ [432 target files]  # ê°ì • ì ìš©ë¨
â”‚   â””â”€â”€ [72 reference files] # ê°ì • ì—†ìŒ, normal-1
â””â”€â”€ expressivity_0.6/        # í…ìŠ¤íŠ¸ì— |0.6 ì¶”ê°€
    â”œâ”€â”€ [432 target files]   # ê°ì • ì ìš©ë¨
    â””â”€â”€ [72 reference files] # ê°ì • ì—†ìŒ, normal-1

Reference ë§¤ì¹­ ê·œì¹™ (IMPLEMENTED):
- v001_match_emo_angry_scale_*.wav â†’ v001_match_reference_angry.wav
- v002_neutral_vec_excited_scale_*.wav â†’ v002_neutral_reference_excited.wav
- v001_opposite_emo_happy_scale_*.wav â†’ v001_opposite_reference_happy.wav

ìë™ ë§¤ì¹­ ê³µì‹: {voice_id}_{text_type}_reference_{emotion}.wav
- voice_id: ë™ì¼í•œ í™”ì
- text_type: ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ í˜• (match/neutral/opposite)  
- emotion: ë™ì¼í•œ ê°ì •ì˜ í…ìŠ¤íŠ¸ ë‚´ìš© (ê°ì •ì€ ì œê±°ë¨)
```

### 3. Reference Connection Implementation (ACTIVE)

#### 3.1 ìë™ Reference ë§¤ì¹­ ì‹œìŠ¤í…œ
```javascript
// ì‹¤ì œ êµ¬í˜„ëœ ë§¤ì¹­ ë¡œì§ (src/lib/sampleData.ts)
function getReferenceFilename(sample: TTSSample): string {
  return `${sample.voice_id}_${sample.text_type}_reference_${sample.emotion_value}.wav`;
}

// ì˜ˆì‹œ ë§¤ì¹­
Target:    "v001_match_emo_angry_scale_1.5.wav"
Reference: "v001_match_reference_angry.wav"
Text:      "I can't believe you broke your promise again!" (ë™ì¼)
Emotion:   Target(angry ì ìš©) vs Reference(ê°ì • ì—†ìŒ, normal-1)
```

#### 3.2 UIì—ì„œì˜ Reference í‘œì‹œ
```typescript
// AudioPlayer ì»´í¬ë„ŒíŠ¸ì—ì„œ ìë™ìœ¼ë¡œ reference í‘œì‹œ
<AudioPlayer sample={sample} isReference={true} />  // Reference audio
<AudioPlayer sample={sample} isReference={false} /> // Target audio

// ê° target sampleë§ˆë‹¤ matching referenceê°€ ìë™ìœ¼ë¡œ í•¨ê»˜ í‘œì‹œë¨
```

#### 3.3 Reference ê²€ì¦ ì™„ë£Œ
```
âœ“ 144ê°œ reference íŒŒì¼ ìƒì„± ì™„ë£Œ (72 Ã— 2 expressivity)
âœ“ ìë™ ë§¤ì¹­ ë¡œì§ êµ¬í˜„ ì™„ë£Œ (getReferenceFilename í•¨ìˆ˜)
âœ“ UI ì—°ê²° ì™„ë£Œ (AudioPlayer ì»´í¬ë„ŒíŠ¸)
âœ“ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ëª¨ë“  voice Ã— emotion Ã— text_type ì¡°í•©)
```

### 4. ìƒ˜í”Œë§ ì „ëµ (Dynamic Random Sampling)

```python
sampling_strategy = {
    "method": "dynamic_random_with_auto_reference",
    "total_target_samples": 432,  # 2 voice Ã— 12 emotion Ã— 3 text Ã— 6 scale (per expressivity)
    "total_reference_samples": 72,  # 2 voice Ã— 12 emotion Ã— 3 text (no emotion, per expressivity)
    "total_unique_texts": 72,  # Each emotion Ã— text_type has unique content
    "samples_per_session": 25,  # ì„¸ì…˜ë‹¹ ëœë¤ ì„ íƒ (targets only)
    "total_sessions": 56,  # 14ëª… Ã— 4ì„¸ì…˜
    "total_evaluations": 1400,  # 56 Ã— 25
    
    "coverage_analysis": {
        "avg_evals_per_sample": 3.24,  # 1400 / 432
        "min_1_eval_probability": "96.2%",
        "min_2_evals_probability": "78%"
    },
    
    "sampling_rules": {
        "ë§¤ ì„¸ì…˜ë§ˆë‹¤": "432ê°œ target ì¤‘ 25ê°œ ìƒˆë¡œ ëœë¤ ì„ íƒ",
        "ì¤‘ë³µ í—ˆìš©": "ì„¸ì…˜ ê°„ ì¤‘ë³µ ê°€ëŠ¥, ì„¸ì…˜ ë‚´ ì¤‘ë³µ ë¶ˆê°€",
        "reference ìë™ í‘œì‹œ": "ê° targetê³¼ ë§¤ì¹­ë˜ëŠ” reference ìë™ í‘œì‹œ (êµ¬í˜„ì™„ë£Œ)",
        "reference ë§¤ì¹­": "voice_id + emotion + text_typeì´ ê°™ì€ reference ì—°ê²° (êµ¬í˜„ì™„ë£Œ)",
        "ê· í˜• ìœ ì§€": "ì™„ì „ ëœë¤ì´ì§€ë§Œ extreme bias ë°©ì§€",
        "í…ìŠ¤íŠ¸ ê³ ìœ ì„±": "ê° emotion Ã— text_type ì¡°í•©ì€ ê³ ìœ í•œ í…ìŠ¤íŠ¸ ì‚¬ìš© (72ê°œ unique)",
        "ì‹¤ì‹œê°„ ì—°ê²°": "UIì—ì„œ target ì„ íƒì‹œ matching reference ì¦‰ì‹œ í‘œì‹œ"
    },
    
    "expected_power": {
        "voice_effect": 0.99,
        "text_effect": 0.95,
        "emotion_effect": 0.75,
        "scale_effect": 0.88,
        "overall": 0.85  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€ë¡œ ì•½ê°„ ê°ì†Œ
    }
}
```

## ğŸ’» êµ¬í˜„ ì»´í¬ë„ŒíŠ¸

### Phase 1: ìŒì„± ìƒì„± ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```python
# í•„ìš”í•œ ëª¨ë“ˆë“¤
modules = {
    "ConfigManager": "í…ŒìŠ¤íŠ¸ ì„¤ì • ë° íŒŒë¼ë¯¸í„° ê´€ë¦¬",
    "APIClient": "TTS API í˜¸ì¶œ ë° ì—ëŸ¬ ì²˜ë¦¬",
    "FileManager": "ìŒì„± íŒŒì¼ ì €ì¥ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬",
    "TestGenerator": "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¡°í•© ìƒì„±",
    "BatchProcessor": "ëŒ€ëŸ‰ ìš”ì²­ ì²˜ë¦¬ ë° rate limiting",
    "ReferenceManager": "ì˜¤ë””ì˜¤/í”„ë¡¬í”„íŠ¸ ë ˆí¼ëŸ°ìŠ¤ ê´€ë¦¬"
}

# TTS API ì›Œí¬í”Œë¡œìš° (4ë‹¨ê³„ ë¹„ë™ê¸° ì²˜ë¦¬)
# API ì œì•½ì‚¬í•­ ë° ê·œì¹™ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë°˜)
api_constraints = {
    "style_label": "í•­ìƒ 'normal-1' ê³ ì • (ë‹¤ë¥¸ ê°’ ì§€ì› ì•ˆí•¨)",
    "emotion_control": "emotion_label ë˜ëŠ” emotion_vector_id ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©",
    "mutual_exclusion": "emotion_vector_id ì‚¬ìš©ì‹œ emotion_labelì€ None/ë¹ˆê°’",
    "emotion_scale": "0.5 ~ 3.0 ë²”ìœ„ì—ì„œ ê°ì • ê°•ë„ ì¡°ì ˆ"
}

api_workflow = {
    "step1_request": {
        "url": "https://dev.icepeak.ai/api/speak/batch/post",
        "method": "POST",
        "headers": {"Authorization": "Bearer TOKEN"},
        "data": [
            {
                "text": "string",
                "actor_id": "string (voice_001: 688b02990486383d463c9d1a, voice_002: 689c693264acbc0a5b9fb0e5)", 
                "style_label": "normal-1",  # í•­ìƒ ê³ ì •ê°’
                "emotion_label": "string (optional, emotion_vector_idì™€ ìƒí˜¸ë°°íƒ€)",
                "emotion_vector_id": "string (optional, emotion_labelê³¼ ìƒí˜¸ë°°íƒ€)",
                "emotion_scale": "float (0.5-3.0)",
                "tempo": 1,
                "pitch": 0,
                "lang": "auto",
                "mode": "one-vocoder",
                "retake": True,
                "adjust_lastword": 0,
                "style_label_version": "v1"
            }
        ],
        "response": {"result": {"speak_urls": ["url1", "url2"]}}
    },
    
    "step2_poll": {
        "url": "https://dev.icepeak.ai/api/speak/batch/get", 
        "method": "POST",
        "headers": {"Authorization": "Bearer TOKEN"},
        "data": ["speak_url1", "speak_url2"],
        "polling": "5ì´ˆë§ˆë‹¤ ìµœëŒ€ 20íšŒ ì‹œë„",
        "response": {"result": [{"status": "done", "audio": {"url": "audio_url"}}]}
    },
    
    "step3_get_download_url": {
        "url": "{audio_url}/cloudfront",
        "method": "GET", 
        "headers": {"Authorization": "Bearer TOKEN"},
        "response": {"result": "final_download_url"}
    },
    
    "step4_download": {
        "url": "final_download_url",
        "method": "GET",
        "headers": "none",
        "response": "binary audio data"
    }
}

# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ íŒŒì¼ ì°¸ì¡°
test_sentences_reference = {
    "file": "tts-test-sentences.md",
    "purpose": "ê° ê°ì •ë³„ 3ê°€ì§€ ìœ í˜•ì˜ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ì œê³µ",
    "structure": {
        "match": "ê°ì •ê³¼ ì–´ìš¸ë¦¬ëŠ” ë‚´ìš©",
        "neutral": "ê°ì •ê³¼ ë¬´ê´€í•œ ì¤‘ë¦½ì  ë‚´ìš©", 
        "opposite": "í•´ë‹¹ ê°ì •ê³¼ ë°˜ëŒ€ë˜ëŠ” ë‚´ìš©"
    },
    "emotions": [
        "Angry", "Sad", "Happy", "Whisper", "Toneup", "Tonedown",
        "Excited", "Furious", "Terrified", "ë‘ë ¤ì›€", "ë†€ëŒ", "í¥ë¶„"
    ],
    "usage": "ê° ê°ì •ì˜ style_label ë˜ëŠ” emotion_vector_idì™€ ë§¤í•‘í•˜ì—¬ ì‚¬ìš©"
}

# ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘
reference_mapping = {
    "audio1": "path/to/audio_reference_1.wav",
    "audio2": "path/to/audio_reference_2.wav",
    "audio3": "path/to/audio_reference_3.wav",
    "prompt1": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 1",
    "prompt2": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 2",
    "prompt3": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 3"
}
```

#### êµ¬í˜„ ìˆœì„œ
1. **ì„¤ì • íŒŒì¼ ìƒì„±** (`config.yaml`)
   ```yaml
   api:
     endpoint: "YOUR_API_ENDPOINT"
     rate_limit: 10  # requests per second
     retry_attempts: 3
   
   storage:
     output_dir: "./generated_voices"
     metadata_db: "./metadata.db"
     reference_dir: "./references"
   
   test_parameters:
     voice_ids: ["voice_001", "voice_002"]
     texts: ["text_1", "text_2", "text_3"]
     
     emotion_vectors:
       audio_based:
         - name: "excited"
           id: "68a6b0ca2edfc11a25045538"
           reference: "references/audio/excited.wav"
         - name: "furious"
           id: "68a6b0d2b436060efdc6bc80"
           reference: "references/audio/furious.wav"
         - name: "terrified"
           id: "68a6b0d9b436060efdc6bc82"
           reference: "references/audio/terrified.wav"
       
       prompt_based:
         - name: "ë‘ë ¤ì›€"
           id: "68a6b0f7b436060efdc6bc83"
           prompt: "ë‘ë ¤ì›€ì´ ê°€ë“í•œ ëª©ì†Œë¦¬"
         - name: "ë†€ëŒ"
           id: "68a6b10255e3b2836e609969"
           prompt: "ë†€ë€ ëª©ì†Œë¦¬"
         - name: "í¥ë¶„"
           id: "68a6b1062edfc11a2504553b"
           prompt: "í¥ë¶„ëœ ëª©ì†Œë¦¬"
     
     style_labels: ["normal-1", "style-2", "style-3", "style-4", "style-5", "style-6", "style-7"]
     emotion_scales: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
   ```

2. **ìƒ˜í”Œë§ ë° ìƒì„±**
   ```python
   def generate_full_sample_pool():
       """
       1. ì „ì²´ 432ê°œ ì¡°í•© ìƒì„±
          - 2 voice Ã— 3 text Ã— 6 reference = 6ê°œ
          - 2 voice Ã— 3 text Ã— 12 emotion Ã— 6 scale = 432ê°œ
       2. ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ìŒì„± ìƒì„±
       3. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
       """
       samples = []
       
       # Reference ìƒ˜í”Œ (6ê°œ)
       for voice in voices:
           for text in texts:
               samples.append({
                   'type': 'reference',
                   'style_label': 'normal-1',
                   'emotion_scale': 1.0
               })
       
       # Style ìƒ˜í”Œ (216ê°œ)
       for voice in voices:
           for text in texts:
               for style in style_labels[1:]:  # normal-1 ì œì™¸
                   for scale in emotion_scales:
                       samples.append({
                           'type': 'style',
                           'style_label': style,
                           'emotion_scale': scale
                       })
       
       # Emotion vector ìƒ˜í”Œ (216ê°œ)
       for voice in voices:
           for text in texts:
               for emotion_vector in emotion_vectors:
                   for scale in emotion_scales:
                       samples.append({
                           'type': 'emotion_vector',
                           'emotion_vector_id': emotion_vector,
                           'style_label': 'normal-1',
                           'emotion_scale': scale
                       })
       
       return samples  # ì´ 438ê°œ (6 ref + 432 variations)
   
   def get_session_samples():
       """
       1. 438ê°œ í’€ì—ì„œ 25ê°œ ëœë¤ ì„ íƒ
       2. ì„¸ì…˜ ID ìƒì„±
       3. ì„ íƒëœ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
       4. ë¡œê·¸ì— ì„¸ì…˜ë³„ ìƒ˜í”Œ ê¸°ë¡
       """
       import random
       import uuid
       
       all_samples = load_all_samples()  # 438ê°œ
       session_samples = random.sample(all_samples, 25)
       session_id = str(uuid.uuid4())
       
       return {
           'session_id': session_id,
           'samples': session_samples
       }
   ```

### Phase 2: QA í…ŒìŠ¤íŠ¸ í”Œë«í¼ - Vercel ë°°í¬

#### 2.0 ë°°í¬ ì „ëµ (Updated with Supabase Integration)
```yaml
deployment:
  platform: "Vercel"
  repository: "https://github.com/sagheepark/ssfm_qa.git"
  framework: "Next.js 14 with App Router"
  audio_hosting: "Supabase Storage"
  database: "Supabase PostgreSQL"
  realtime: "Supabase Real-time subscriptions"
  
workflow:
  1. "âœ… Create Next.js TTS QA application" 
  2. "âœ… Push to GitHub repository (without large audio files)"
  3. "âœ… Deploy to Vercel with automatic CD/CI"
  4. "ğŸ”„ Setup Supabase project for audio storage & database"
  5. "ğŸ”„ Upload all 252 audio files (216 samples + 36 references) to Supabase Storage"
  6. "ğŸ”„ Create evaluation response tables in Supabase"
  7. "ğŸ”„ Update app to use Supabase URLs for audio files"

supabase_integration:
  storage:
    bucket: "tts-audio-samples"
    structure: "/voices/{filename}.wav"
    cdn_delivery: "Global edge cache for fast audio loading"
    
  database_schema:
    tables:
      - "qa_sessions (session_id, user_id, started_at, completed_at)"
      - "sample_evaluations (session_id, sample_id, quality, emotion, similarity, comment, timestamp)"
      - "sample_metadata (sample_id, filename, voice_id, text_type, emotion_type, scale, text_content)"
      
  advantages:
    - "Audio files served from CDN (faster loading)"
    - "28MB+ audio files don't count against Vercel limits"
    - "Database for response analysis and aggregation"
    - "Real-time progress tracking across evaluators"
    - "Scalable for multiple evaluation sessions"

features:
  - "âœ… Single Page Application (SPA)"
  - "âœ… Dynamic random sampling (25 samples per session)"
  - "âœ… Client-side progress tracking with localStorage"
  - "âœ… Mobile-responsive design"
  - "ğŸ”„ Audio streaming from Supabase Storage CDN"
  - "ğŸ”„ Real-time evaluation data collection"
  - "ğŸ”„ Progress analytics dashboard"
```

#### 2.1 í‰ê°€ ì²´ê³„ (Vercel ìµœì í™”)

```python
evaluation_axes = {
    "í€„ë¦¬í‹°": {
        "description": "ìŒì„±ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆ ë° ê¸°ìˆ ì  ì™„ì„±ë„",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ë²½í•œ í’ˆì§ˆ, ìƒìš© ìˆ˜ì¤€",
            6: "ë§¤ìš° ì¢‹ì€ í’ˆì§ˆ",
            5: "ì¢‹ì€ í’ˆì§ˆ, ë¯¸ì„¸í•œ ë¬¸ì œ",
            4: "ë³´í†µ, ëˆˆì— ë„ëŠ” ë¬¸ì œ ìˆìŒ",
            3: "í’ˆì§ˆ ë¬¸ì œ ìˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥",
            2: "ì‹¬ê°í•œ í’ˆì§ˆ ë¬¸ì œ",
            1: "ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ìˆ˜ì¤€"
        },
        "sub_items": ["ë…¸ì´ì¦ˆ", "í´ë¦¬í•‘", "ëŠê¹€", "ì„ ëª…ë„"]
    },
    "ê°ì •_í‘œí˜„ë ¥": {
        "description": "ì˜ë„í•œ ê°ì •ì´ ì–¼ë§ˆë‚˜ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ê°€",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ë²½í•œ ê°ì • í‘œí˜„",
            6: "ë§¤ìš° ì¢‹ì€ ê°ì • í‘œí˜„",
            5: "ì¢‹ì€ ê°ì • í‘œí˜„",
            4: "ë³´í†µì˜ ê°ì • í‘œí˜„",
            3: "ë¶€ì¡±í•œ ê°ì • í‘œí˜„",
            2: "ë§¤ìš° ë¶€ì¡±í•œ ê°ì • í‘œí˜„",
            1: "ê°ì •ì´ ì „í˜€ í‘œí˜„ë˜ì§€ ì•ŠìŒ"
        },
        "reference_required": True  # audio/prompt reference í‘œì‹œ
    },
    "í™”ì_ìœ ì‚¬ë„": {
        "description": "ì›ë³¸ í™”ìì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œê°€",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ì „íˆ ë™ì¼í•œ í™”ì",
            6: "ê±°ì˜ ë™ì¼í•œ í™”ì",
            5: "ìœ ì‚¬í•˜ì§€ë§Œ ì•½ê°„ì˜ ì°¨ì´",
            4: "ë¹„ìŠ·í•œ í¸",
            3: "ì°¨ì´ê°€ ëŠê»´ì§",
            2: "í™•ì‹¤íˆ ë‹¤ë¥¸ í™”ì",
            1: "ì™„ì „íˆ ë‹¤ë¥¸ í™”ì"
        },
        "reference_audio": "í•„ìˆ˜"
    }
}
```

#### 2.2 ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¡° (Updated with Editable Results)

```markdown
### ë‹¨ì¼ í˜ì´ì§€ í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤
1. **ì‹œì‘ í™”ë©´**
   - ê°„ë‹¨í•œ ì•ˆë‚´ ë¬¸êµ¬
   - "í…ŒìŠ¤íŠ¸ ì‹œì‘" ë²„íŠ¼
   - ì˜ˆìƒ ì†Œìš” ì‹œê°„ í‘œì‹œ

2. **í‰ê°€ í™”ë©´ (Enhanced Navigation & UX)**
   - ì§„í–‰ë¥  í‘œì‹œ (í˜„ì¬/ì „ì²´)
   - Reference ìŒì„± ì¬ìƒ
   - ë ˆí¼ëŸ°ìŠ¤ í‘œì‹œ:
     * Audio Reference: ì›ë³¸ ì˜¤ë””ì˜¤ ì¬ìƒ ë²„íŠ¼
     * Prompt Reference: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
   - í…ŒìŠ¤íŠ¸ ìŒì„± ì¬ìƒ
   - 3ì¶• í‰ê°€ ì…ë ¥ (7ì  ì²™ë„)
   - ì„ íƒì  ì½”ë©˜íŠ¸ ì…ë ¥
   - **Enhanced Navigation:**
     * Previous button (always available)
     * **Primary CTA Next button (prominent, only active when all 3 scores filled)**
     * Separated control section:
       - Reset Session button (destructive action)
       - Stop & Submit button (saves all data to database)
   
3. **ì¢…ë£Œ í™”ë©´**
   - ì™„ë£Œ ë©”ì‹œì§€ (after Stop & Submit or completing all samples)
   - Session summary (number of samples evaluated)
   - "ìƒˆ ì„¸ì…˜ ì‹œì‘" ë²„íŠ¼

### Enhanced State Management & Data Flow
- **Local-only evaluation storage**: Results stored in localStorage only
- **No per-sample database writes**: Individual evaluations NOT saved to database immediately
- **Batch data submission**: All evaluations saved to database only when:
  - User clicks "Stop & Submit" (partial completion)
  - User completes all 25 samples (full completion)
- **Editable results**: Users can navigate back/forth and modify previous answers
- **Smart navigation**: Next button prominent and disabled until current sample is fully evaluated
- **Session persistence**: localStorage maintains progress across browser sessions
```

#### 2.3 í‰ê°€ ì„¤ê³„ (Dynamic Sampling)

```python
evaluation_design = {
    "evaluators": "ìµëª… (êµ¬ë¶„ ì—†ìŒ)",
    "target_sessions": 56,  # 14ëª… Ã— 4ì„¸ì…˜ ëª©í‘œ
    "samples_per_session": 25,  # ë§¤ ì„¸ì…˜ ìƒˆë¡œìš´ 25ê°œ
    
    "dynamic_sampling": {
        "method": "ë§¤ ì„¸ì…˜ë§ˆë‹¤ 438ê°œ ì¤‘ 25ê°œ ëœë¤ ì„ íƒ",
        "benefit": "ëª¨ë“  ìƒ˜í”Œì´ í‰ê·  3.2íšŒ í‰ê°€",
        "coverage": "96% ìƒ˜í”Œì´ ìµœì†Œ 1íšŒ ì´ìƒ í‰ê°€"
    },
    
    "session_structure": {
        "warm_up": 2,  # ì—°ìŠµìš© ìƒ˜í”Œ
        "actual": 25,  # ì‹¤ì œ í‰ê°€ ìƒ˜í”Œ
        "navigation": ["ì´ì „", "ë‹¤ìŒ", "ì²˜ìŒë¶€í„°"],
        "progress_save": "localStorage (ìë™)"
    },
    
    "data_collection": {
        "storage": "JSON íŒŒì¼",
        "format": {
            "session_id": "unique per session",
            "timestamp": "datetime",
            "sample_id": "string",
            "scores": {
                "quality": "1-7",
                "emotion": "1-7",
                "similarity": "1-7"
            },
            "comment": "optional string"
        }
    }
}

# Flask ì„œë²„ - Dynamic Sampling
flask_server = """
from flask import Flask, jsonify, request
import json
import random
import uuid
from datetime import datetime

app = Flask(__name__)

@app.route('/api/get-session-samples')
def get_session_samples():
    # ë§¤ ìš”ì²­ë§ˆë‹¤ 438ê°œ ì¤‘ 25ê°œë¥¼ ìƒˆë¡œ ëœë¤ ì„ íƒ
    all_samples = load_all_samples()  # 438ê°œ ì „ì²´ (6 ref + 432 variations)
    session_samples = random.sample(all_samples, 25)
    session_id = str(uuid.uuid4())
    
    # ì„¸ì…˜ ë¡œê·¸ ì €ì¥ (ì–´ë–¤ ìƒ˜í”Œì´ ì„ íƒë˜ì—ˆëŠ”ì§€)
    log_session_samples(session_id, session_samples)
    
    return jsonify({
        'session_id': session_id,
        'samples': session_samples,
        'total': 25
    })

@app.route('/api/save-result', methods=['POST'])
def save_result():
    data = request.json
    data['timestamp'] = datetime.now().isoformat()
    
    with open('data/results.json', 'a') as f:
        json.dump(data, f)
        f.write('\\n')
    
    return jsonify({'status': 'success'})
"""
```

### Phase 3: ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŒ…

#### 3.1 Mixed Effects Model ë¶„ì„

```python
analysis_model = """
Quality_Score = Î²â‚€ + Î²â‚(voice) + Î²â‚‚(text) + Î²â‚ƒ(emotion) + Î²â‚„(scale) 
                + Î²â‚…(emotionÃ—scale) + Î²â‚†(emotion_type) 
                + random(evaluator) + random(sample) + Îµ

where:
- random(sample): ìƒ˜í”Œë³„ ë‚œì´ë„ ì°¨ì´ ë³´ì • (ë™ì  ìƒ˜í”Œë§ì˜ ì´ì )
- emotion_type: audio_based vs prompt_based vs style_based
- scale: ëª¨ë“  emotion typeì— ì ìš©ë˜ëŠ” ì—°ì† ë³€ìˆ˜
- ê° ë³€ìˆ˜ì˜ ì£¼íš¨ê³¼ ë° ìƒí˜¸ì‘ìš© ë¶„ì„
- í‰ê°€ì íš¨ê³¼ ë³´ì •
"""

expected_results = {
    "voice_effect": "p < 0.01, ê²€ì •ë ¥ 0.99",
    "text_effect": "p < 0.01, ê²€ì •ë ¥ 0.95",
    "emotion_main_effect": "p < 0.01, ê²€ì •ë ¥ 0.75",
    "scale_effect": "p < 0.01, ê²€ì •ë ¥ 0.88",
    "emotionÃ—scale_interaction": "style vs vectorì˜ scale ë°˜ì‘ ì°¨ì´",
    "overall_power": "0.85 (438ê°œ ìƒ˜í”Œ, ë™ì  ìƒ˜í”Œë§)",
    "coverage": "96% ìƒ˜í”Œì´ í‰ê°€ë˜ì–´ ëŒ€ë¶€ë¶„ ì¡°í•© í¬ì°©"
}
```

#### 3.2 ìë™ í’ˆì§ˆ ê²€ì‚¬

```python
automatic_checks = {
    "silence_detection": "ë¬´ìŒ êµ¬ê°„ ê°ì§€",
    "clipping_detection": "í´ë¦¬í•‘ ë°œìƒ ê°ì§€",
    "duration_check": "ë¹„ì •ìƒì  ê¸¸ì´ ê°ì§€",
    "volume_analysis": "ë³¼ë¥¨ ë ˆë²¨ ì´ìƒ ê°ì§€",
    "noise_level": "SNR ì¸¡ì •"
}
```

#### 3.3 í†µê³„ ë¶„ì„ ë©”íŠ¸ë¦­

```python
analysis_metrics = {
    "parameter_impact": {
        "emotion_scale vs í€„ë¦¬í‹°": "ì„ í˜•/ë¹„ì„ í˜• ê´€ê³„ ë¶„ì„",
        "emotion_typeë³„ ê°ì •í‘œí˜„ë ¥": "audio/prompt/style ë¹„êµ",
        "voice_idë³„ í™”ììœ ì‚¬ë„": "í™”ìë³„ ì•ˆì •ì„± ë¶„ì„"
    },
    
    "threshold_analysis": {
        "critical_cases": "ì ìˆ˜ < 4ì¸ ì¼€ì´ìŠ¤ ë¶„ì„",
        "high_performers": "ì ìˆ˜ â‰¥ 6ì¸ ì¼€ì´ìŠ¤ ë¶„ì„",
        "parameter_patterns": "ë¬¸ì œ ë°œìƒ íŒŒë¼ë¯¸í„° ì¡°í•©"
    },
    
    "reference_effectiveness": {
        "audio_vs_prompt": "ë ˆí¼ëŸ°ìŠ¤ íƒ€ì…ë³„ íš¨ê³¼ì„±",
        "scale_optimization": "ìµœì  emotion_scale ê°’ ë„ì¶œ"
    }
}
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° (ê°„ì†Œí™”)

```
tts-qa-system/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ test_parameters.json
â”œâ”€â”€ references/
â”‚   â”œâ”€â”€ audio/           # ì˜¤ë””ì˜¤ ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ excited.wav
â”‚   â”‚   â”œâ”€â”€ furious.wav
â”‚   â”‚   â””â”€â”€ terrified.wav
â”‚   â””â”€â”€ prompts/         # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
â”‚       â””â”€â”€ prompts.json
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_voices.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â”œâ”€â”€ sampling_strategy.py
â”‚   â””â”€â”€ batch_processor.py
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py           # ê°„ë‹¨í•œ Flask ì„œë²„
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ index.html   # ë‹¨ì¼ í˜ì´ì§€ ì•±
â”‚   â”‚   â”œâ”€â”€ app.js       # í‰ê°€ ë¡œì§ ë° ìƒíƒœ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ styles.css   # ìŠ¤íƒ€ì¼
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ results.json # í‰ê°€ ê²°ê³¼ ì €ì¥
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ mixed_effects_model.py
â”‚   â””â”€â”€ report_generator.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ voices/          # ìƒì„±ëœ ìŒì„± íŒŒì¼
â””â”€â”€ requirements.txt
```

## ğŸš€ êµ¬í˜„ ë‹¨ê³„ë³„ ê°€ì´ë“œ (Dynamic Sampling)

### Step 1: í™˜ê²½ ì„¤ì • ë° ë ˆí¼ëŸ°ìŠ¤ ì¤€ë¹„ (Day 1)
```bash
# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
mkdir tts-qa-system
cd tts-qa-system
python -m venv venv
source venv/bin/activate

# ìµœì†Œ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜
pip install flask requests pyyaml pandas numpy
```

### Step 2: ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Day 2-3)
1. ì „ì²´ 438ê°œ ìƒ˜í”Œ ì¡°í•© ìƒì„±
   - Reference: 6ê°œ (2 voice Ã— 3 text)
   - Style variations: 216ê°œ (2 Ã— 3 Ã— 6 style Ã— 6 scale)
   - Emotion vector variations: 216ê°œ (2 Ã— 3 Ã— 6 vector Ã— 6 scale)
2. API í˜¸ì¶œë¡œ ëª¨ë“  ìŒì„± ìƒì„±
3. íŒŒì¼ëª… ê·œì¹™ì— ë”°ë¼ ì €ì¥
4. ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° JSON ìƒì„±

### Step 3: ê°„ë‹¨í•œ ì›¹ ì•± êµ¬ì¶• (Day 3-4)
1. ë‹¨ì¼ HTML í˜ì´ì§€ (SPA)
2. ì„¸ì…˜ ì‹œì‘ ì‹œ ì„œë²„ì—ì„œ 25ê°œ ëœë¤ ìƒ˜í”Œ ë°›ê¸°
3. localStorageë¡œ ì§„í–‰ ìƒí™© ê´€ë¦¬
4. Flaskë¡œ ìƒ˜í”Œ ì œê³µ ë° ê²°ê³¼ ì €ì¥ API êµ¬í˜„

### Step 4: í…ŒìŠ¤íŠ¸ ë° ë°ì´í„° ìˆ˜ì§‘ (Day 5-8)
1. í‰ê°€ìë“¤ì—ê²Œ ë§í¬ ë°°í¬
2. ê°ì í¸í•œ ì‹œê°„ì— 25ê°œì”© 4ì„¸ì…˜ ì§„í–‰
3. ë§¤ ì„¸ì…˜ë§ˆë‹¤ ë‹¤ë¥¸ ìƒ˜í”Œ ì„¸íŠ¸ í‰ê°€
4. JSON íŒŒì¼ë¡œ ê²°ê³¼ ìˆ˜ì§‘

### Step 5: ë¶„ì„ (Day 9)
1. ìˆ˜ì§‘ëœ JSON ë°ì´í„° íŒŒì‹±
2. ìƒ˜í”Œë³„ í‰ê°€ íšŸìˆ˜ í™•ì¸
3. Mixed Effects Model ë¶„ì„
4. Style vs Emotion Vectorì˜ scale ë°˜ì‘ ì°¨ì´ ë¶„ì„
5. ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼ë¬¼

### 1. ìƒì„±ëœ ë°ì´í„°
- ìŒì„± íŒŒì¼: 438ê°œ (6 reference + 432 variations)
- ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘: JSON íŒŒì¼ë¡œ ê´€ë¦¬
- í‰ê°€ ë°ì´í„°: ~1,400ê°œ (56ì„¸ì…˜ Ã— 25ìƒ˜í”Œ)

### 2. ìƒ˜í”Œ ì»¤ë²„ë¦¬ì§€
```python
coverage_stats = {
    "ì´ ìƒ˜í”Œ": 438,
    "- Reference": 6,
    "- Style variations": 216,  # 6 styles Ã— 6 scales Ã— 6 combinations
    "- Emotion vector variations": 216,  # 6 vectors Ã— 6 scales Ã— 6 combinations
    "í‰ê·  í‰ê°€ íšŸìˆ˜": 3.2,
    "ìµœì†Œ 1íšŒ í‰ê°€": "96%",
    "ìµœì†Œ 2íšŒ í‰ê°€": "78%",
    "ë¯¸í‰ê°€ ìƒ˜í”Œ": "< 4%"
}
```

### 3. ìˆ˜ì§‘ ë°ì´í„° í˜•ì‹
```json
{
  "session_id": "unique-uuid-per-session",
  "timestamp": "2024-01-01T10:30:00",
  "sample_id": "v001_t001_style_happy-1_scale_2.0",
  "scores": {
    "quality": 5,
    "emotion": 6,
    "similarity": 4
  },
  "comment": "optional comment",
  "duration_ms": 8500
}
```

### 4. ë¶„ì„ ë¦¬í¬íŠ¸
- ë³€ìˆ˜ë³„ ì£¼íš¨ê³¼ ë¶„ì„ (ê²€ì •ë ¥ 0.85)
- Style vs Emotion Vectorì˜ scale ë¯¼ê°ë„ ë¹„êµ
- Scaleì´ ê° emotion typeì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- Audio vs Prompt ê¸°ë°˜ emotion vector íš¨ê³¼ì„± ë¹„êµ

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**: localStorage ì§€ì› ë¸Œë¼ìš°ì € í™•ì¸
2. **ë°ì´í„° ë°±ì—…**: results.json ì£¼ê¸°ì  ë°±ì—…
3. **ìƒ˜í”Œ ê´€ë¦¬**: 438ê°œ ì „ì²´ ìƒ˜í”Œ íŒŒì¼ ì„œë²„ì— ì¤€ë¹„
4. **ì„¸ì…˜ ë¡œê¹…**: ê° ì„¸ì…˜ì—ì„œ ì–´ë–¤ ìƒ˜í”Œì´ ì„ íƒë˜ì—ˆëŠ”ì§€ ê¸°ë¡
5. **ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ**: ì›¹ ì„œë²„ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
6. **Scale ì ìš©**: ëª¨ë“  emotion (style_label, emotion_vector)ì— scale ì ìš© í™•ì¸

## ğŸ”„ í–¥í›„ ê°œì„  ì‚¬í•­

1. **ì ì‘í˜• ìƒ˜í”Œë§**: ì´ˆê¸° ê²°ê³¼ ê¸°ë°˜ ì¶”ê°€ ìƒ˜í”Œë§
2. **ìë™ í’ˆì§ˆ í‰ê°€**: ML ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
3. **A/B í…ŒìŠ¤íŠ¸**: ëª¨ë¸ ë²„ì „ ê°„ ë¹„êµ
4. **ì‹¤ì‹œê°„ ë¶„ì„**: í‰ê°€ ì§„í–‰ ì¤‘ ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸

---

ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ Cursorì™€ í•¨ê»˜ ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ êµ¬í˜„í•˜ì‹œë©´ ë©ë‹ˆë‹¤. íŠ¹íˆ ë ˆí¼ëŸ°ìŠ¤ ì²˜ë¦¬ì™€ ìƒ˜í”Œë§ ì „ëµì´ í•µì‹¬ì…ë‹ˆë‹¤.