# TTS QA ìë™í™” í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ê³„íšì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
Text-to-Speech ëª¨ë¸ì˜ í’ˆì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ ê²€ì¦í•˜ê¸° ìœ„í•œ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

### í•µì‹¬ ëª©í‘œ
1. ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ì— ëŒ€í•œ ìŒì„± ìë™ ìƒì„±
2. Reference ìŒì„± ëŒ€ë¹„ í’ˆì§ˆ í‰ê°€
3. ë³€ìˆ˜ë³„ ì˜í–¥ë„ íŒŒì•… ë° ë¬¸ì œ íŒ¨í„´ ì‹ë³„

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. í…ŒìŠ¤íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤

```
ì´ í…ŒìŠ¤íŠ¸ ê³µê°„ = 432ê°œ ìƒ˜í”Œ
- voice_id: 2ê°œ
- text: 3ê°œ (ê° ê°ì •ë³„ë¡œ match, neutral, opposite)
- emotions: 12ê°œ (emotion_label 6ê°œ + emotion_vector_id 6ê°œ)
- emotion_scale: 6ë‹¨ê³„ (0.5, 1.0, 1.5, 2.0, 2.5, 3.0)

ì‹¤ì œ ê³„ì‚°: 2 voices Ã— 3 text_types Ã— 12 emotions Ã— 6 scales = 432ê°œ ìƒ˜í”Œ
```

#### íŒŒë¼ë¯¸í„° ìƒì„¸

**Emotion êµ¬ì„± (12ê°œ)**
```yaml
emotion_labels: 
  - angry    # "I can't believe you broke your promise again!"
  - sad      # "I really miss the old days when everyone was here together."
  - happy    # "I'm so thrilled about the wonderful surprise party!"
  - whisper  # "Don't make any noise, everyone is sleeping in the next room."
  - toneup   # "Did you really win the grand prize in the competition?"
  - tonedown # "Let me explain this matter in a very serious manner."

emotion_vector_ids:
  - 68a6b0ca2edfc11a25045538  # Excited: "We're going on the adventure of a lifetime!"
  - 68a6b0d2b436060efdc6bc80  # Furious: "This is absolutely unacceptable and I demand an explanation!"
  - 68a6b0d9b436060efdc6bc82  # Terrified: "Something is moving in the shadows and I don't know what!"
  - 68a6b0f7b436060efdc6bc83  # ë‘ë ¤ì›€: "I'm really scared about what might happen if this goes wrong."
  - 68a6b10255e3b2836e609969  # ë†€ëŒ: "Oh my goodness, I never expected to see you here today!"
  - 68a6b1062edfc11a2504553b  # í¥ë¶„: "I can hardly wait to share this amazing news with everyone!"

emotion_scales: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]

text_types: [match, neutral, opposite]  # ê°ì • ì¼ì¹˜, ì¤‘ë¦½, ë°˜ëŒ€
```

#### íŒŒë¼ë¯¸í„° ê·œì¹™
- `style_label`ê³¼ `emotion_vector_id`ëŠ” ìƒí˜¸ ë°°íƒ€ì 
- `emotion_vector_id` ì‚¬ìš© ì‹œ â†’ `style_label = "normal-1"`
- `style_label â‰  "normal-1"` ì‹œ â†’ `emotion_vector_id` ì œê±°
- `emotion_scale`ì€ `emotion_vector_id` ì‚¬ìš© ì‹œì—ë§Œ ì ìš©

#### Reference ìŒì„± ì •ì˜
ê° `voice_id Ã— text` ì¡°í•©ë‹¹ 1ê°œì˜ reference ìŒì„±:
- `style_label: "normal-1"`
- `emotion_vector_id: null`
- `emotion_scale: 1.0`

### 2. íŒŒì¼ëª… ê·œì¹™

```
í˜•ì‹: {voice_id}_{text_type}_{emotion_type}_{emotion_value}_{scale}.wav

ì˜ˆì‹œ:
- emotion_label: v001_match_emo_angry_scale_1.5.wav
- emotion_vector_id: v001_neutral_vec_excited_scale_2.0.wav
- Reference (no emotion): v001_ref_neutral.wav

text_type: match, neutral, opposite
emotion_type: emo (emotion_label), vec (emotion_vector_id), ref (reference)
```

### 3. ìƒ˜í”Œë§ ì „ëµ (Dynamic Random Sampling)

```python
sampling_strategy = {
    "method": "dynamic_random",
    "total_sample_pool": 432,  # 2 voice Ã— 3 text Ã— 12 emotion Ã— 6 scale
    "samples_per_session": 25,  # ì„¸ì…˜ë‹¹ ëœë¤ ì„ íƒ
    "total_sessions": 56,  # 14ëª… Ã— 4ì„¸ì…˜
    "total_evaluations": 1400,  # 56 Ã— 25
    
    "coverage_analysis": {
        "avg_evals_per_sample": 3.24,  # 1400 / 432
        "min_1_eval_probability": "96.2%",
        "min_2_evals_probability": "78%"
    },
    
    "sampling_rules": {
        "ë§¤ ì„¸ì…˜ë§ˆë‹¤": "432ê°œ ì¤‘ 25ê°œ ìƒˆë¡œ ëœë¤ ì„ íƒ",
        "ì¤‘ë³µ í—ˆìš©": "ì„¸ì…˜ ê°„ ì¤‘ë³µ ê°€ëŠ¥, ì„¸ì…˜ ë‚´ ì¤‘ë³µ ë¶ˆê°€",
        "reference í¬í•¨": "ê°€ëŠ¥í•˜ë©´ ê° ì„¸ì…˜ì— 1-2ê°œ reference",
        "ê· í˜• ìœ ì§€": "ì™„ì „ ëœë¤ì´ì§€ë§Œ extreme bias ë°©ì§€"
    },
    
    "expected_power": {
        "voice_effect": 0.99,
        "text_effect": 0.95,
        "emotion_effect": 0.75,
        "scale_effect": 0.88,
        "overall": 0.85  # ìƒ˜í”Œ ìˆ˜ ì¦ê°€ë¡œ ì•½ê°„ ê°ì†Œ
    }
}
```

## ğŸ’» êµ¬í˜„ ì»´í¬ë„ŒíŠ¸

### Phase 1: ìŒì„± ìƒì„± ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```python
# í•„ìš”í•œ ëª¨ë“ˆë“¤
modules = {
    "ConfigManager": "í…ŒìŠ¤íŠ¸ ì„¤ì • ë° íŒŒë¼ë¯¸í„° ê´€ë¦¬",
    "APIClient": "TTS API í˜¸ì¶œ ë° ì—ëŸ¬ ì²˜ë¦¬",
    "FileManager": "ìŒì„± íŒŒì¼ ì €ì¥ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬",
    "TestGenerator": "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¡°í•© ìƒì„±",
    "BatchProcessor": "ëŒ€ëŸ‰ ìš”ì²­ ì²˜ë¦¬ ë° rate limiting",
    "ReferenceManager": "ì˜¤ë””ì˜¤/í”„ë¡¬í”„íŠ¸ ë ˆí¼ëŸ°ìŠ¤ ê´€ë¦¬"
}

# TTS API ì›Œí¬í”Œë¡œìš° (4ë‹¨ê³„ ë¹„ë™ê¸° ì²˜ë¦¬)
# API ì œì•½ì‚¬í•­ ë° ê·œì¹™ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë°˜)
api_constraints = {
    "style_label": "í•­ìƒ 'normal-1' ê³ ì • (ë‹¤ë¥¸ ê°’ ì§€ì› ì•ˆí•¨)",
    "emotion_control": "emotion_label ë˜ëŠ” emotion_vector_id ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©",
    "mutual_exclusion": "emotion_vector_id ì‚¬ìš©ì‹œ emotion_labelì€ None/ë¹ˆê°’",
    "emotion_scale": "0.5 ~ 3.0 ë²”ìœ„ì—ì„œ ê°ì • ê°•ë„ ì¡°ì ˆ"
}

api_workflow = {
    "step1_request": {
        "url": "https://dev.icepeak.ai/api/speak/batch/post",
        "method": "POST",
        "headers": {"Authorization": "Bearer TOKEN"},
        "data": [
            {
                "text": "string",
                "actor_id": "string (voice_001: 688b02990486383d463c9d1a, voice_002: 689c693264acbc0a5b9fb0e5)", 
                "style_label": "normal-1",  # í•­ìƒ ê³ ì •ê°’
                "emotion_label": "string (optional, emotion_vector_idì™€ ìƒí˜¸ë°°íƒ€)",
                "emotion_vector_id": "string (optional, emotion_labelê³¼ ìƒí˜¸ë°°íƒ€)",
                "emotion_scale": "float (0.5-3.0)",
                "tempo": 1,
                "pitch": 0,
                "lang": "auto",
                "mode": "one-vocoder",
                "retake": True,
                "adjust_lastword": 0,
                "style_label_version": "v1"
            }
        ],
        "response": {"result": {"speak_urls": ["url1", "url2"]}}
    },
    
    "step2_poll": {
        "url": "https://dev.icepeak.ai/api/speak/batch/get", 
        "method": "POST",
        "headers": {"Authorization": "Bearer TOKEN"},
        "data": ["speak_url1", "speak_url2"],
        "polling": "5ì´ˆë§ˆë‹¤ ìµœëŒ€ 20íšŒ ì‹œë„",
        "response": {"result": [{"status": "done", "audio": {"url": "audio_url"}}]}
    },
    
    "step3_get_download_url": {
        "url": "{audio_url}/cloudfront",
        "method": "GET", 
        "headers": {"Authorization": "Bearer TOKEN"},
        "response": {"result": "final_download_url"}
    },
    
    "step4_download": {
        "url": "final_download_url",
        "method": "GET",
        "headers": "none",
        "response": "binary audio data"
    }
}

# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ íŒŒì¼ ì°¸ì¡°
test_sentences_reference = {
    "file": "tts-test-sentences.md",
    "purpose": "ê° ê°ì •ë³„ 3ê°€ì§€ ìœ í˜•ì˜ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ì œê³µ",
    "structure": {
        "match": "ê°ì •ê³¼ ì–´ìš¸ë¦¬ëŠ” ë‚´ìš©",
        "neutral": "ê°ì •ê³¼ ë¬´ê´€í•œ ì¤‘ë¦½ì  ë‚´ìš©", 
        "opposite": "í•´ë‹¹ ê°ì •ê³¼ ë°˜ëŒ€ë˜ëŠ” ë‚´ìš©"
    },
    "emotions": [
        "Angry", "Sad", "Happy", "Whisper", "Toneup", "Tonedown",
        "Excited", "Furious", "Terrified", "ë‘ë ¤ì›€", "ë†€ëŒ", "í¥ë¶„"
    ],
    "usage": "ê° ê°ì •ì˜ style_label ë˜ëŠ” emotion_vector_idì™€ ë§¤í•‘í•˜ì—¬ ì‚¬ìš©"
}

# ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘
reference_mapping = {
    "audio1": "path/to/audio_reference_1.wav",
    "audio2": "path/to/audio_reference_2.wav",
    "audio3": "path/to/audio_reference_3.wav",
    "prompt1": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 1",
    "prompt2": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 2",
    "prompt3": "ê°ì • í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ 3"
}
```

#### êµ¬í˜„ ìˆœì„œ
1. **ì„¤ì • íŒŒì¼ ìƒì„±** (`config.yaml`)
   ```yaml
   api:
     endpoint: "YOUR_API_ENDPOINT"
     rate_limit: 10  # requests per second
     retry_attempts: 3
   
   storage:
     output_dir: "./generated_voices"
     metadata_db: "./metadata.db"
     reference_dir: "./references"
   
   test_parameters:
     voice_ids: ["voice_001", "voice_002"]
     texts: ["text_1", "text_2", "text_3"]
     
     emotion_vectors:
       audio_based:
         - name: "excited"
           id: "68a6b0ca2edfc11a25045538"
           reference: "references/audio/excited.wav"
         - name: "furious"
           id: "68a6b0d2b436060efdc6bc80"
           reference: "references/audio/furious.wav"
         - name: "terrified"
           id: "68a6b0d9b436060efdc6bc82"
           reference: "references/audio/terrified.wav"
       
       prompt_based:
         - name: "ë‘ë ¤ì›€"
           id: "68a6b0f7b436060efdc6bc83"
           prompt: "ë‘ë ¤ì›€ì´ ê°€ë“í•œ ëª©ì†Œë¦¬"
         - name: "ë†€ëŒ"
           id: "68a6b10255e3b2836e609969"
           prompt: "ë†€ë€ ëª©ì†Œë¦¬"
         - name: "í¥ë¶„"
           id: "68a6b1062edfc11a2504553b"
           prompt: "í¥ë¶„ëœ ëª©ì†Œë¦¬"
     
     style_labels: ["normal-1", "style-2", "style-3", "style-4", "style-5", "style-6", "style-7"]
     emotion_scales: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
   ```

2. **ìƒ˜í”Œë§ ë° ìƒì„±**
   ```python
   def generate_full_sample_pool():
       """
       1. ì „ì²´ 432ê°œ ì¡°í•© ìƒì„±
          - 2 voice Ã— 3 text Ã— 6 reference = 6ê°œ
          - 2 voice Ã— 3 text Ã— 12 emotion Ã— 6 scale = 432ê°œ
       2. ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ìŒì„± ìƒì„±
       3. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
       """
       samples = []
       
       # Reference ìƒ˜í”Œ (6ê°œ)
       for voice in voices:
           for text in texts:
               samples.append({
                   'type': 'reference',
                   'style_label': 'normal-1',
                   'emotion_scale': 1.0
               })
       
       # Style ìƒ˜í”Œ (216ê°œ)
       for voice in voices:
           for text in texts:
               for style in style_labels[1:]:  # normal-1 ì œì™¸
                   for scale in emotion_scales:
                       samples.append({
                           'type': 'style',
                           'style_label': style,
                           'emotion_scale': scale
                       })
       
       # Emotion vector ìƒ˜í”Œ (216ê°œ)
       for voice in voices:
           for text in texts:
               for emotion_vector in emotion_vectors:
                   for scale in emotion_scales:
                       samples.append({
                           'type': 'emotion_vector',
                           'emotion_vector_id': emotion_vector,
                           'style_label': 'normal-1',
                           'emotion_scale': scale
                       })
       
       return samples  # ì´ 438ê°œ (6 ref + 432 variations)
   
   def get_session_samples():
       """
       1. 438ê°œ í’€ì—ì„œ 25ê°œ ëœë¤ ì„ íƒ
       2. ì„¸ì…˜ ID ìƒì„±
       3. ì„ íƒëœ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
       4. ë¡œê·¸ì— ì„¸ì…˜ë³„ ìƒ˜í”Œ ê¸°ë¡
       """
       import random
       import uuid
       
       all_samples = load_all_samples()  # 438ê°œ
       session_samples = random.sample(all_samples, 25)
       session_id = str(uuid.uuid4())
       
       return {
           'session_id': session_id,
           'samples': session_samples
       }
   ```

### Phase 2: QA í…ŒìŠ¤íŠ¸ í”Œë«í¼ - Vercel ë°°í¬

#### 2.0 ë°°í¬ ì „ëµ (Updated with Supabase Integration)
```yaml
deployment:
  platform: "Vercel"
  repository: "https://github.com/sagheepark/ssfm_qa.git"
  framework: "Next.js 14 with App Router"
  audio_hosting: "Supabase Storage"
  database: "Supabase PostgreSQL"
  realtime: "Supabase Real-time subscriptions"
  
workflow:
  1. "âœ… Create Next.js TTS QA application" 
  2. "âœ… Push to GitHub repository (without large audio files)"
  3. "âœ… Deploy to Vercel with automatic CD/CI"
  4. "ğŸ”„ Setup Supabase project for audio storage & database"
  5. "ğŸ”„ Upload all 252 audio files (216 samples + 36 references) to Supabase Storage"
  6. "ğŸ”„ Create evaluation response tables in Supabase"
  7. "ğŸ”„ Update app to use Supabase URLs for audio files"

supabase_integration:
  storage:
    bucket: "tts-audio-samples"
    structure: "/voices/{filename}.wav"
    cdn_delivery: "Global edge cache for fast audio loading"
    
  database_schema:
    tables:
      - "qa_sessions (session_id, user_id, started_at, completed_at)"
      - "sample_evaluations (session_id, sample_id, quality, emotion, similarity, comment, timestamp)"
      - "sample_metadata (sample_id, filename, voice_id, text_type, emotion_type, scale, text_content)"
      
  advantages:
    - "Audio files served from CDN (faster loading)"
    - "28MB+ audio files don't count against Vercel limits"
    - "Database for response analysis and aggregation"
    - "Real-time progress tracking across evaluators"
    - "Scalable for multiple evaluation sessions"

features:
  - "âœ… Single Page Application (SPA)"
  - "âœ… Dynamic random sampling (25 samples per session)"
  - "âœ… Client-side progress tracking with localStorage"
  - "âœ… Mobile-responsive design"
  - "ğŸ”„ Audio streaming from Supabase Storage CDN"
  - "ğŸ”„ Real-time evaluation data collection"
  - "ğŸ”„ Progress analytics dashboard"
```

#### 2.1 í‰ê°€ ì²´ê³„ (Vercel ìµœì í™”)

```python
evaluation_axes = {
    "í€„ë¦¬í‹°": {
        "description": "ìŒì„±ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆ ë° ê¸°ìˆ ì  ì™„ì„±ë„",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ë²½í•œ í’ˆì§ˆ, ìƒìš© ìˆ˜ì¤€",
            6: "ë§¤ìš° ì¢‹ì€ í’ˆì§ˆ",
            5: "ì¢‹ì€ í’ˆì§ˆ, ë¯¸ì„¸í•œ ë¬¸ì œ",
            4: "ë³´í†µ, ëˆˆì— ë„ëŠ” ë¬¸ì œ ìˆìŒ",
            3: "í’ˆì§ˆ ë¬¸ì œ ìˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥",
            2: "ì‹¬ê°í•œ í’ˆì§ˆ ë¬¸ì œ",
            1: "ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ìˆ˜ì¤€"
        },
        "sub_items": ["ë…¸ì´ì¦ˆ", "í´ë¦¬í•‘", "ëŠê¹€", "ì„ ëª…ë„"]
    },
    "ê°ì •_í‘œí˜„ë ¥": {
        "description": "ì˜ë„í•œ ê°ì •ì´ ì–¼ë§ˆë‚˜ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ê°€",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ë²½í•œ ê°ì • í‘œí˜„",
            6: "ë§¤ìš° ì¢‹ì€ ê°ì • í‘œí˜„",
            5: "ì¢‹ì€ ê°ì • í‘œí˜„",
            4: "ë³´í†µì˜ ê°ì • í‘œí˜„",
            3: "ë¶€ì¡±í•œ ê°ì • í‘œí˜„",
            2: "ë§¤ìš° ë¶€ì¡±í•œ ê°ì • í‘œí˜„",
            1: "ê°ì •ì´ ì „í˜€ í‘œí˜„ë˜ì§€ ì•ŠìŒ"
        },
        "reference_required": True  # audio/prompt reference í‘œì‹œ
    },
    "í™”ì_ìœ ì‚¬ë„": {
        "description": "ì›ë³¸ í™”ìì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œê°€",
        "scale": [1, 2, 3, 4, 5, 6, 7],
        "guidelines": {
            7: "ì™„ì „íˆ ë™ì¼í•œ í™”ì",
            6: "ê±°ì˜ ë™ì¼í•œ í™”ì",
            5: "ìœ ì‚¬í•˜ì§€ë§Œ ì•½ê°„ì˜ ì°¨ì´",
            4: "ë¹„ìŠ·í•œ í¸",
            3: "ì°¨ì´ê°€ ëŠê»´ì§",
            2: "í™•ì‹¤íˆ ë‹¤ë¥¸ í™”ì",
            1: "ì™„ì „íˆ ë‹¤ë¥¸ í™”ì"
        },
        "reference_audio": "í•„ìˆ˜"
    }
}
```

#### 2.2 ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¡° (ê°„ì†Œí™”)

```markdown
### ë‹¨ì¼ í˜ì´ì§€ í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤
1. **ì‹œì‘ í™”ë©´**
   - ê°„ë‹¨í•œ ì•ˆë‚´ ë¬¸êµ¬
   - "í…ŒìŠ¤íŠ¸ ì‹œì‘" ë²„íŠ¼
   - ì˜ˆìƒ ì†Œìš” ì‹œê°„ í‘œì‹œ

2. **í‰ê°€ í™”ë©´**
   - ì§„í–‰ë¥  í‘œì‹œ (í˜„ì¬/ì „ì²´)
   - Reference ìŒì„± ì¬ìƒ
   - ë ˆí¼ëŸ°ìŠ¤ í‘œì‹œ:
     * Audio Reference: ì›ë³¸ ì˜¤ë””ì˜¤ ì¬ìƒ ë²„íŠ¼
     * Prompt Reference: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
   - í…ŒìŠ¤íŠ¸ ìŒì„± ì¬ìƒ
   - 3ì¶• í‰ê°€ ì…ë ¥ (7ì  ì²™ë„)
   - ì„ íƒì  ì½”ë©˜íŠ¸ ì…ë ¥
   - ë„¤ë¹„ê²Œì´ì…˜:
     * ì´ì „ ë¬¸ì œë¡œ
     * ë‹¤ìŒ ë¬¸ì œë¡œ
     * ì²˜ìŒë¶€í„° ë‹¤ì‹œ
   
3. **ì¢…ë£Œ í™”ë©´**
   - ì™„ë£Œ ë©”ì‹œì§€
   - "ìƒˆ ì„¸ì…˜ ì‹œì‘" ë²„íŠ¼

### ë¡œì»¬ ìƒíƒœ ê´€ë¦¬
- localStorage í™œìš©í•œ ì§„í–‰ ìƒí™© ì €ì¥
- ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨/íƒ­ ì „í™˜ ì‹œì—ë„ ìœ ì§€
- ëª…ì‹œì  ë¦¬ì…‹ ë²„íŠ¼ìœ¼ë¡œë§Œ ì´ˆê¸°í™”
```

#### 2.3 í‰ê°€ ì„¤ê³„ (Dynamic Sampling)

```python
evaluation_design = {
    "evaluators": "ìµëª… (êµ¬ë¶„ ì—†ìŒ)",
    "target_sessions": 56,  # 14ëª… Ã— 4ì„¸ì…˜ ëª©í‘œ
    "samples_per_session": 25,  # ë§¤ ì„¸ì…˜ ìƒˆë¡œìš´ 25ê°œ
    
    "dynamic_sampling": {
        "method": "ë§¤ ì„¸ì…˜ë§ˆë‹¤ 438ê°œ ì¤‘ 25ê°œ ëœë¤ ì„ íƒ",
        "benefit": "ëª¨ë“  ìƒ˜í”Œì´ í‰ê·  3.2íšŒ í‰ê°€",
        "coverage": "96% ìƒ˜í”Œì´ ìµœì†Œ 1íšŒ ì´ìƒ í‰ê°€"
    },
    
    "session_structure": {
        "warm_up": 2,  # ì—°ìŠµìš© ìƒ˜í”Œ
        "actual": 25,  # ì‹¤ì œ í‰ê°€ ìƒ˜í”Œ
        "navigation": ["ì´ì „", "ë‹¤ìŒ", "ì²˜ìŒë¶€í„°"],
        "progress_save": "localStorage (ìë™)"
    },
    
    "data_collection": {
        "storage": "JSON íŒŒì¼",
        "format": {
            "session_id": "unique per session",
            "timestamp": "datetime",
            "sample_id": "string",
            "scores": {
                "quality": "1-7",
                "emotion": "1-7",
                "similarity": "1-7"
            },
            "comment": "optional string"
        }
    }
}

# Flask ì„œë²„ - Dynamic Sampling
flask_server = """
from flask import Flask, jsonify, request
import json
import random
import uuid
from datetime import datetime

app = Flask(__name__)

@app.route('/api/get-session-samples')
def get_session_samples():
    # ë§¤ ìš”ì²­ë§ˆë‹¤ 438ê°œ ì¤‘ 25ê°œë¥¼ ìƒˆë¡œ ëœë¤ ì„ íƒ
    all_samples = load_all_samples()  # 438ê°œ ì „ì²´ (6 ref + 432 variations)
    session_samples = random.sample(all_samples, 25)
    session_id = str(uuid.uuid4())
    
    # ì„¸ì…˜ ë¡œê·¸ ì €ì¥ (ì–´ë–¤ ìƒ˜í”Œì´ ì„ íƒë˜ì—ˆëŠ”ì§€)
    log_session_samples(session_id, session_samples)
    
    return jsonify({
        'session_id': session_id,
        'samples': session_samples,
        'total': 25
    })

@app.route('/api/save-result', methods=['POST'])
def save_result():
    data = request.json
    data['timestamp'] = datetime.now().isoformat()
    
    with open('data/results.json', 'a') as f:
        json.dump(data, f)
        f.write('\\n')
    
    return jsonify({'status': 'success'})
"""
```

### Phase 3: ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŒ…

#### 3.1 Mixed Effects Model ë¶„ì„

```python
analysis_model = """
Quality_Score = Î²â‚€ + Î²â‚(voice) + Î²â‚‚(text) + Î²â‚ƒ(emotion) + Î²â‚„(scale) 
                + Î²â‚…(emotionÃ—scale) + Î²â‚†(emotion_type) 
                + random(evaluator) + random(sample) + Îµ

where:
- random(sample): ìƒ˜í”Œë³„ ë‚œì´ë„ ì°¨ì´ ë³´ì • (ë™ì  ìƒ˜í”Œë§ì˜ ì´ì )
- emotion_type: audio_based vs prompt_based vs style_based
- scale: ëª¨ë“  emotion typeì— ì ìš©ë˜ëŠ” ì—°ì† ë³€ìˆ˜
- ê° ë³€ìˆ˜ì˜ ì£¼íš¨ê³¼ ë° ìƒí˜¸ì‘ìš© ë¶„ì„
- í‰ê°€ì íš¨ê³¼ ë³´ì •
"""

expected_results = {
    "voice_effect": "p < 0.01, ê²€ì •ë ¥ 0.99",
    "text_effect": "p < 0.01, ê²€ì •ë ¥ 0.95",
    "emotion_main_effect": "p < 0.01, ê²€ì •ë ¥ 0.75",
    "scale_effect": "p < 0.01, ê²€ì •ë ¥ 0.88",
    "emotionÃ—scale_interaction": "style vs vectorì˜ scale ë°˜ì‘ ì°¨ì´",
    "overall_power": "0.85 (438ê°œ ìƒ˜í”Œ, ë™ì  ìƒ˜í”Œë§)",
    "coverage": "96% ìƒ˜í”Œì´ í‰ê°€ë˜ì–´ ëŒ€ë¶€ë¶„ ì¡°í•© í¬ì°©"
}
```

#### 3.2 ìë™ í’ˆì§ˆ ê²€ì‚¬

```python
automatic_checks = {
    "silence_detection": "ë¬´ìŒ êµ¬ê°„ ê°ì§€",
    "clipping_detection": "í´ë¦¬í•‘ ë°œìƒ ê°ì§€",
    "duration_check": "ë¹„ì •ìƒì  ê¸¸ì´ ê°ì§€",
    "volume_analysis": "ë³¼ë¥¨ ë ˆë²¨ ì´ìƒ ê°ì§€",
    "noise_level": "SNR ì¸¡ì •"
}
```

#### 3.3 í†µê³„ ë¶„ì„ ë©”íŠ¸ë¦­

```python
analysis_metrics = {
    "parameter_impact": {
        "emotion_scale vs í€„ë¦¬í‹°": "ì„ í˜•/ë¹„ì„ í˜• ê´€ê³„ ë¶„ì„",
        "emotion_typeë³„ ê°ì •í‘œí˜„ë ¥": "audio/prompt/style ë¹„êµ",
        "voice_idë³„ í™”ììœ ì‚¬ë„": "í™”ìë³„ ì•ˆì •ì„± ë¶„ì„"
    },
    
    "threshold_analysis": {
        "critical_cases": "ì ìˆ˜ < 4ì¸ ì¼€ì´ìŠ¤ ë¶„ì„",
        "high_performers": "ì ìˆ˜ â‰¥ 6ì¸ ì¼€ì´ìŠ¤ ë¶„ì„",
        "parameter_patterns": "ë¬¸ì œ ë°œìƒ íŒŒë¼ë¯¸í„° ì¡°í•©"
    },
    
    "reference_effectiveness": {
        "audio_vs_prompt": "ë ˆí¼ëŸ°ìŠ¤ íƒ€ì…ë³„ íš¨ê³¼ì„±",
        "scale_optimization": "ìµœì  emotion_scale ê°’ ë„ì¶œ"
    }
}
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° (ê°„ì†Œí™”)

```
tts-qa-system/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ test_parameters.json
â”œâ”€â”€ references/
â”‚   â”œâ”€â”€ audio/           # ì˜¤ë””ì˜¤ ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ excited.wav
â”‚   â”‚   â”œâ”€â”€ furious.wav
â”‚   â”‚   â””â”€â”€ terrified.wav
â”‚   â””â”€â”€ prompts/         # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
â”‚       â””â”€â”€ prompts.json
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_voices.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â”œâ”€â”€ sampling_strategy.py
â”‚   â””â”€â”€ batch_processor.py
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py           # ê°„ë‹¨í•œ Flask ì„œë²„
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ index.html   # ë‹¨ì¼ í˜ì´ì§€ ì•±
â”‚   â”‚   â”œâ”€â”€ app.js       # í‰ê°€ ë¡œì§ ë° ìƒíƒœ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ styles.css   # ìŠ¤íƒ€ì¼
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ results.json # í‰ê°€ ê²°ê³¼ ì €ì¥
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ mixed_effects_model.py
â”‚   â””â”€â”€ report_generator.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ voices/          # ìƒì„±ëœ ìŒì„± íŒŒì¼
â””â”€â”€ requirements.txt
```

## ğŸš€ êµ¬í˜„ ë‹¨ê³„ë³„ ê°€ì´ë“œ (Dynamic Sampling)

### Step 1: í™˜ê²½ ì„¤ì • ë° ë ˆí¼ëŸ°ìŠ¤ ì¤€ë¹„ (Day 1)
```bash
# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
mkdir tts-qa-system
cd tts-qa-system
python -m venv venv
source venv/bin/activate

# ìµœì†Œ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜
pip install flask requests pyyaml pandas numpy
```

### Step 2: ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Day 2-3)
1. ì „ì²´ 438ê°œ ìƒ˜í”Œ ì¡°í•© ìƒì„±
   - Reference: 6ê°œ (2 voice Ã— 3 text)
   - Style variations: 216ê°œ (2 Ã— 3 Ã— 6 style Ã— 6 scale)
   - Emotion vector variations: 216ê°œ (2 Ã— 3 Ã— 6 vector Ã— 6 scale)
2. API í˜¸ì¶œë¡œ ëª¨ë“  ìŒì„± ìƒì„±
3. íŒŒì¼ëª… ê·œì¹™ì— ë”°ë¼ ì €ì¥
4. ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° JSON ìƒì„±

### Step 3: ê°„ë‹¨í•œ ì›¹ ì•± êµ¬ì¶• (Day 3-4)
1. ë‹¨ì¼ HTML í˜ì´ì§€ (SPA)
2. ì„¸ì…˜ ì‹œì‘ ì‹œ ì„œë²„ì—ì„œ 25ê°œ ëœë¤ ìƒ˜í”Œ ë°›ê¸°
3. localStorageë¡œ ì§„í–‰ ìƒí™© ê´€ë¦¬
4. Flaskë¡œ ìƒ˜í”Œ ì œê³µ ë° ê²°ê³¼ ì €ì¥ API êµ¬í˜„

### Step 4: í…ŒìŠ¤íŠ¸ ë° ë°ì´í„° ìˆ˜ì§‘ (Day 5-8)
1. í‰ê°€ìë“¤ì—ê²Œ ë§í¬ ë°°í¬
2. ê°ì í¸í•œ ì‹œê°„ì— 25ê°œì”© 4ì„¸ì…˜ ì§„í–‰
3. ë§¤ ì„¸ì…˜ë§ˆë‹¤ ë‹¤ë¥¸ ìƒ˜í”Œ ì„¸íŠ¸ í‰ê°€
4. JSON íŒŒì¼ë¡œ ê²°ê³¼ ìˆ˜ì§‘

### Step 5: ë¶„ì„ (Day 9)
1. ìˆ˜ì§‘ëœ JSON ë°ì´í„° íŒŒì‹±
2. ìƒ˜í”Œë³„ í‰ê°€ íšŸìˆ˜ í™•ì¸
3. Mixed Effects Model ë¶„ì„
4. Style vs Emotion Vectorì˜ scale ë°˜ì‘ ì°¨ì´ ë¶„ì„
5. ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼ë¬¼

### 1. ìƒì„±ëœ ë°ì´í„°
- ìŒì„± íŒŒì¼: 438ê°œ (6 reference + 432 variations)
- ë ˆí¼ëŸ°ìŠ¤ ë§¤í•‘: JSON íŒŒì¼ë¡œ ê´€ë¦¬
- í‰ê°€ ë°ì´í„°: ~1,400ê°œ (56ì„¸ì…˜ Ã— 25ìƒ˜í”Œ)

### 2. ìƒ˜í”Œ ì»¤ë²„ë¦¬ì§€
```python
coverage_stats = {
    "ì´ ìƒ˜í”Œ": 438,
    "- Reference": 6,
    "- Style variations": 216,  # 6 styles Ã— 6 scales Ã— 6 combinations
    "- Emotion vector variations": 216,  # 6 vectors Ã— 6 scales Ã— 6 combinations
    "í‰ê·  í‰ê°€ íšŸìˆ˜": 3.2,
    "ìµœì†Œ 1íšŒ í‰ê°€": "96%",
    "ìµœì†Œ 2íšŒ í‰ê°€": "78%",
    "ë¯¸í‰ê°€ ìƒ˜í”Œ": "< 4%"
}
```

### 3. ìˆ˜ì§‘ ë°ì´í„° í˜•ì‹
```json
{
  "session_id": "unique-uuid-per-session",
  "timestamp": "2024-01-01T10:30:00",
  "sample_id": "v001_t001_style_happy-1_scale_2.0",
  "scores": {
    "quality": 5,
    "emotion": 6,
    "similarity": 4
  },
  "comment": "optional comment",
  "duration_ms": 8500
}
```

### 4. ë¶„ì„ ë¦¬í¬íŠ¸
- ë³€ìˆ˜ë³„ ì£¼íš¨ê³¼ ë¶„ì„ (ê²€ì •ë ¥ 0.85)
- Style vs Emotion Vectorì˜ scale ë¯¼ê°ë„ ë¹„êµ
- Scaleì´ ê° emotion typeì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- Audio vs Prompt ê¸°ë°˜ emotion vector íš¨ê³¼ì„± ë¹„êµ

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**: localStorage ì§€ì› ë¸Œë¼ìš°ì € í™•ì¸
2. **ë°ì´í„° ë°±ì—…**: results.json ì£¼ê¸°ì  ë°±ì—…
3. **ìƒ˜í”Œ ê´€ë¦¬**: 438ê°œ ì „ì²´ ìƒ˜í”Œ íŒŒì¼ ì„œë²„ì— ì¤€ë¹„
4. **ì„¸ì…˜ ë¡œê¹…**: ê° ì„¸ì…˜ì—ì„œ ì–´ë–¤ ìƒ˜í”Œì´ ì„ íƒë˜ì—ˆëŠ”ì§€ ê¸°ë¡
5. **ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ**: ì›¹ ì„œë²„ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
6. **Scale ì ìš©**: ëª¨ë“  emotion (style_label, emotion_vector)ì— scale ì ìš© í™•ì¸

## ğŸ”„ í–¥í›„ ê°œì„  ì‚¬í•­

1. **ì ì‘í˜• ìƒ˜í”Œë§**: ì´ˆê¸° ê²°ê³¼ ê¸°ë°˜ ì¶”ê°€ ìƒ˜í”Œë§
2. **ìë™ í’ˆì§ˆ í‰ê°€**: ML ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§
3. **A/B í…ŒìŠ¤íŠ¸**: ëª¨ë¸ ë²„ì „ ê°„ ë¹„êµ
4. **ì‹¤ì‹œê°„ ë¶„ì„**: í‰ê°€ ì§„í–‰ ì¤‘ ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸

---

ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ Cursorì™€ í•¨ê»˜ ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ êµ¬í˜„í•˜ì‹œë©´ ë©ë‹ˆë‹¤. íŠ¹íˆ ë ˆí¼ëŸ°ìŠ¤ ì²˜ë¦¬ì™€ ìƒ˜í”Œë§ ì „ëµì´ í•µì‹¬ì…ë‹ˆë‹¤.